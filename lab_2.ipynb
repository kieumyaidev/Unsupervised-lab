{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af355e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in ./.kenv/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (0.23.0)\n",
      "Requirement already satisfied: torch in ./.kenv/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (2.9.1)\n",
      "Requirement already satisfied: torcheval in ./.kenv/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (0.0.7)\n",
      "Requirement already satisfied: torchvision in ./.kenv/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (0.24.1)\n",
      "Requirement already satisfied: torchaudio in ./.kenv/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (2.9.1)\n",
      "Requirement already satisfied: numpy in ./.kenv/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (2.3.5)\n",
      "Requirement already satisfied: scikit-learn in ./.kenv/lib/python3.12/site-packages (from -r requirements.txt (line 7)) (1.7.2)\n",
      "Requirement already satisfied: tensorflow in ./.kenv/lib/python3.12/site-packages (from -r requirements.txt (line 8)) (2.20.0)\n",
      "Requirement already satisfied: PyWavelets in ./.kenv/lib/python3.12/site-packages (from -r requirements.txt (line 9)) (1.9.0)\n",
      "Requirement already satisfied: scipy in ./.kenv/lib/python3.12/site-packages (from -r requirements.txt (line 10)) (1.16.3)\n",
      "Requirement already satisfied: spectrum in ./.kenv/lib/python3.12/site-packages (from -r requirements.txt (line 11)) (0.9.0)\n",
      "Requirement already satisfied: seaborn in ./.kenv/lib/python3.12/site-packages (from -r requirements.txt (line 12)) (0.13.2)\n",
      "Requirement already satisfied: tqdm in ./.kenv/lib/python3.12/site-packages (from -r requirements.txt (line 13)) (4.67.1)\n",
      "Requirement already satisfied: ucimlrepo in ./.kenv/lib/python3.12/site-packages (from -r requirements.txt (line 16)) (0.0.7)\n",
      "Requirement already satisfied: transformers in ./.kenv/lib/python3.12/site-packages (from -r requirements.txt (line 17)) (4.57.3)\n",
      "Requirement already satisfied: datasets in ./.kenv/lib/python3.12/site-packages (from -r requirements.txt (line 18)) (4.4.1)\n",
      "Requirement already satisfied: tf-keras in ./.kenv/lib/python3.12/site-packages (from -r requirements.txt (line 19)) (2.20.1)\n",
      "Requirement already satisfied: pytest in ./.kenv/lib/python3.12/site-packages (from -r requirements.txt (line 20)) (9.0.1)\n",
      "Requirement already satisfied: click>=8.0.1 in ./.kenv/lib/python3.12/site-packages (from wandb->-r requirements.txt (line 1)) (8.3.1)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in ./.kenv/lib/python3.12/site-packages (from wandb->-r requirements.txt (line 1)) (3.1.45)\n",
      "Requirement already satisfied: packaging in ./.kenv/lib/python3.12/site-packages (from wandb->-r requirements.txt (line 1)) (25.0)\n",
      "Requirement already satisfied: platformdirs in ./.kenv/lib/python3.12/site-packages (from wandb->-r requirements.txt (line 1)) (4.5.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in ./.kenv/lib/python3.12/site-packages (from wandb->-r requirements.txt (line 1)) (6.33.1)\n",
      "Requirement already satisfied: pydantic<3 in ./.kenv/lib/python3.12/site-packages (from wandb->-r requirements.txt (line 1)) (2.12.5)\n",
      "Requirement already satisfied: pyyaml in ./.kenv/lib/python3.12/site-packages (from wandb->-r requirements.txt (line 1)) (6.0.3)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in ./.kenv/lib/python3.12/site-packages (from wandb->-r requirements.txt (line 1)) (2.32.5)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in ./.kenv/lib/python3.12/site-packages (from wandb->-r requirements.txt (line 1)) (2.46.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.8 in ./.kenv/lib/python3.12/site-packages (from wandb->-r requirements.txt (line 1)) (4.15.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.kenv/lib/python3.12/site-packages (from pydantic<3->wandb->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in ./.kenv/lib/python3.12/site-packages (from pydantic<3->wandb->-r requirements.txt (line 1)) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./.kenv/lib/python3.12/site-packages (from pydantic<3->wandb->-r requirements.txt (line 1)) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.kenv/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 1)) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.kenv/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 1)) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.kenv/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 1)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.kenv/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 1)) (2025.11.12)\n",
      "Requirement already satisfied: filelock in ./.kenv/lib/python3.12/site-packages (from torch->-r requirements.txt (line 2)) (3.20.0)\n",
      "Requirement already satisfied: setuptools in ./.kenv/lib/python3.12/site-packages (from torch->-r requirements.txt (line 2)) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.kenv/lib/python3.12/site-packages (from torch->-r requirements.txt (line 2)) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in ./.kenv/lib/python3.12/site-packages (from torch->-r requirements.txt (line 2)) (3.6)\n",
      "Requirement already satisfied: jinja2 in ./.kenv/lib/python3.12/site-packages (from torch->-r requirements.txt (line 2)) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in ./.kenv/lib/python3.12/site-packages (from torch->-r requirements.txt (line 2)) (2025.10.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.kenv/lib/python3.12/site-packages (from torchvision->-r requirements.txt (line 4)) (12.0.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.kenv/lib/python3.12/site-packages (from scikit-learn->-r requirements.txt (line 7)) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.kenv/lib/python3.12/site-packages (from scikit-learn->-r requirements.txt (line 7)) (3.6.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./.kenv/lib/python3.12/site-packages (from tensorflow->-r requirements.txt (line 8)) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./.kenv/lib/python3.12/site-packages (from tensorflow->-r requirements.txt (line 8)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in ./.kenv/lib/python3.12/site-packages (from tensorflow->-r requirements.txt (line 8)) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./.kenv/lib/python3.12/site-packages (from tensorflow->-r requirements.txt (line 8)) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in ./.kenv/lib/python3.12/site-packages (from tensorflow->-r requirements.txt (line 8)) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./.kenv/lib/python3.12/site-packages (from tensorflow->-r requirements.txt (line 8)) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in ./.kenv/lib/python3.12/site-packages (from tensorflow->-r requirements.txt (line 8)) (3.4.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./.kenv/lib/python3.12/site-packages (from tensorflow->-r requirements.txt (line 8)) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./.kenv/lib/python3.12/site-packages (from tensorflow->-r requirements.txt (line 8)) (3.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./.kenv/lib/python3.12/site-packages (from tensorflow->-r requirements.txt (line 8)) (2.0.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./.kenv/lib/python3.12/site-packages (from tensorflow->-r requirements.txt (line 8)) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in ./.kenv/lib/python3.12/site-packages (from tensorflow->-r requirements.txt (line 8)) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in ./.kenv/lib/python3.12/site-packages (from tensorflow->-r requirements.txt (line 8)) (3.12.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in ./.kenv/lib/python3.12/site-packages (from tensorflow->-r requirements.txt (line 8)) (3.15.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in ./.kenv/lib/python3.12/site-packages (from tensorflow->-r requirements.txt (line 8)) (0.5.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./.kenv/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow->-r requirements.txt (line 8)) (3.10)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./.kenv/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow->-r requirements.txt (line 8)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./.kenv/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow->-r requirements.txt (line 8)) (3.1.3)\n",
      "Requirement already satisfied: easydev in ./.kenv/lib/python3.12/site-packages (from spectrum->-r requirements.txt (line 11)) (0.13.3)\n",
      "Requirement already satisfied: matplotlib in ./.kenv/lib/python3.12/site-packages (from spectrum->-r requirements.txt (line 11)) (3.10.7)\n",
      "Requirement already satisfied: pandas>=1.2 in ./.kenv/lib/python3.12/site-packages (from seaborn->-r requirements.txt (line 12)) (2.3.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in ./.kenv/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 17)) (0.36.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.kenv/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 17)) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in ./.kenv/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 17)) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.kenv/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 17)) (0.7.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./.kenv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers->-r requirements.txt (line 17)) (1.2.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in ./.kenv/lib/python3.12/site-packages (from datasets->-r requirements.txt (line 18)) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in ./.kenv/lib/python3.12/site-packages (from datasets->-r requirements.txt (line 18)) (0.4.0)\n",
      "Requirement already satisfied: httpx<1.0.0 in ./.kenv/lib/python3.12/site-packages (from datasets->-r requirements.txt (line 18)) (0.28.1)\n",
      "Requirement already satisfied: xxhash in ./.kenv/lib/python3.12/site-packages (from datasets->-r requirements.txt (line 18)) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in ./.kenv/lib/python3.12/site-packages (from datasets->-r requirements.txt (line 18)) (0.70.18)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./.kenv/lib/python3.12/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 18)) (3.13.2)\n",
      "Requirement already satisfied: anyio in ./.kenv/lib/python3.12/site-packages (from httpx<1.0.0->datasets->-r requirements.txt (line 18)) (4.12.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./.kenv/lib/python3.12/site-packages (from httpx<1.0.0->datasets->-r requirements.txt (line 18)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./.kenv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0->datasets->-r requirements.txt (line 18)) (0.16.0)\n",
      "Requirement already satisfied: iniconfig>=1.0.1 in ./.kenv/lib/python3.12/site-packages (from pytest->-r requirements.txt (line 20)) (2.3.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in ./.kenv/lib/python3.12/site-packages (from pytest->-r requirements.txt (line 20)) (1.6.0)\n",
      "Requirement already satisfied: pygments>=2.7.2 in ./.kenv/lib/python3.12/site-packages (from pytest->-r requirements.txt (line 20)) (2.19.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.kenv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 18)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./.kenv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 18)) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.kenv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 18)) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.kenv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 18)) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.kenv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 18)) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.kenv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 18)) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.kenv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 18)) (1.22.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./.kenv/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow->-r requirements.txt (line 8)) (0.45.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in ./.kenv/lib/python3.12/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 1)) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in ./.kenv/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 1)) (5.0.2)\n",
      "Requirement already satisfied: rich in ./.kenv/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow->-r requirements.txt (line 8)) (14.2.0)\n",
      "Requirement already satisfied: namex in ./.kenv/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow->-r requirements.txt (line 8)) (0.1.0)\n",
      "Requirement already satisfied: optree in ./.kenv/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow->-r requirements.txt (line 8)) (0.18.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.kenv/lib/python3.12/site-packages (from matplotlib->spectrum->-r requirements.txt (line 11)) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.kenv/lib/python3.12/site-packages (from matplotlib->spectrum->-r requirements.txt (line 11)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.kenv/lib/python3.12/site-packages (from matplotlib->spectrum->-r requirements.txt (line 11)) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.kenv/lib/python3.12/site-packages (from matplotlib->spectrum->-r requirements.txt (line 11)) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=3 in ./.kenv/lib/python3.12/site-packages (from matplotlib->spectrum->-r requirements.txt (line 11)) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.kenv/lib/python3.12/site-packages (from matplotlib->spectrum->-r requirements.txt (line 11)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.kenv/lib/python3.12/site-packages (from pandas>=1.2->seaborn->-r requirements.txt (line 12)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.kenv/lib/python3.12/site-packages (from pandas>=1.2->seaborn->-r requirements.txt (line 12)) (2025.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.kenv/lib/python3.12/site-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./.kenv/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow->-r requirements.txt (line 8)) (3.0.3)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.6 in ./.kenv/lib/python3.12/site-packages (from easydev->spectrum->-r requirements.txt (line 11)) (0.4.6)\n",
      "Requirement already satisfied: colorlog<7.0.0,>=6.8.2 in ./.kenv/lib/python3.12/site-packages (from easydev->spectrum->-r requirements.txt (line 11)) (6.10.1)\n",
      "Requirement already satisfied: line-profiler<5.0.0,>=4.1.2 in ./.kenv/lib/python3.12/site-packages (from easydev->spectrum->-r requirements.txt (line 11)) (4.2.0)\n",
      "Requirement already satisfied: pexpect<5.0.0,>=4.9.0 in ./.kenv/lib/python3.12/site-packages (from easydev->spectrum->-r requirements.txt (line 11)) (4.9.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.kenv/lib/python3.12/site-packages (from pexpect<5.0.0,>=4.9.0->easydev->spectrum->-r requirements.txt (line 11)) (0.7.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.kenv/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow->-r requirements.txt (line 8)) (4.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.kenv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow->-r requirements.txt (line 8)) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fdf83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== LIBRARY IMPORTS AND SETUP =====\n",
    "\n",
    "# PyTorch libraries for deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# torchvision for datasets and transforms\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "# NumPy for numerical operations\n",
    "import numpy as np\n",
    "\n",
    "# Scikit-learn for clustering and evaluation metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import normalized_mutual_info_score, adjusted_rand_score, silhouette_score\n",
    "\n",
    "# Check for available device (GPU/CPU/MPS for Apple Silicon)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(\"Device =\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27b411f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== DATA LOADING AND PREPARATION =====\n",
    "# Fashion-MNIST Dataset Setup\n",
    "\n",
    "# Define transformation pipeline for images\n",
    "# Convert images to tensors (normalizes to [0,1] range)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Download and load Fashion-MNIST dataset\n",
    "# Fashion-MNIST contains 70,000 grayscale images (28x28) of 10 fashion categories\n",
    "# - Training set: 60,000 images\n",
    "# - Test set: 10,000 images\n",
    "train_ds = FashionMNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "test_ds  = FashionMNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "# Create DataLoaders for batch processing\n",
    "# DataLoader handles shuffling, batching, and parallel loading\n",
    "train_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
    "test_loader  = DataLoader(test_ds, batch_size=128, shuffle=False)\n",
    "\n",
    "print(f\"Training set size: {len(train_ds)} images\")\n",
    "print(f\"Test set size: {len(test_ds)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3179cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== AUTOENCODER MODEL =====\n",
    "# Standard Autoencoder for learning latent representations\n",
    "\n",
    "class AE(nn.Module):\n",
    "    \"\"\"\n",
    "    Standard Autoencoder (AE) for unsupervised representation learning.\n",
    "    \n",
    "    Architecture:\n",
    "    - Encoder: 784 → 256 → latent_dim\n",
    "    - Decoder: latent_dim → 256 → 784\n",
    "    - Uses ReLU activations\n",
    "    - Output layer uses Sigmoid to match input range [0,1]\n",
    "    \n",
    "    The autoencoder learns to compress images into a lower-dimensional\n",
    "    latent space and reconstruct them, capturing the most important features.\n",
    "    \"\"\"\n",
    "    def __init__(self, latent_dim=32):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Encoder: compresses input to latent representation\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Flatten(),                    # Convert 28×28 image to 784-dim vector\n",
    "            nn.Linear(784, 256), nn.ReLU(),  # First encoding layer\n",
    "            nn.Linear(256, latent_dim)       # Latent representation\n",
    "        )\n",
    "        \n",
    "        # Decoder: reconstructs image from latent representation\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256), nn.ReLU(),  # First decoding layer\n",
    "            nn.Linear(256, 784),                   # Output to original dimension\n",
    "            nn.Sigmoid()                           # Sigmoid for [0,1] output range\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        \"\"\"Encode input to latent space\"\"\"\n",
    "        return self.encoder(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Full autoencoder forward pass\"\"\"\n",
    "        z = self.encoder(x)  # Get latent representation\n",
    "        x_hat = self.decoder(z).view(-1, 1, 28, 28)  # Reconstruct and reshape\n",
    "        return x_hat, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98d50fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, latent_dim=16):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(784, 256), nn.ReLU(),\n",
    "            nn.Linear(256, 64), nn.ReLU()\n",
    "        )\n",
    "        self.mu = nn.Linear(64, latent_dim)\n",
    "        self.logvar = nn.Linear(64, latent_dim)\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 64), nn.ReLU(),\n",
    "            nn.Linear(64, 256), nn.ReLU(),\n",
    "            nn.Linear(256, 784), nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        return self.mu(h), self.logvar(h)\n",
    "    \n",
    "    def reparam(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparam(mu, logvar)\n",
    "        x_hat = self.decoder(z).view(-1, 1, 28, 28)\n",
    "        return x_hat, mu, logvar, z\n",
    "\n",
    "def vae_loss(x_hat, x, mu, logvar):\n",
    "    recon = nn.functional.mse_loss(x_hat, x, reduction=\"sum\")\n",
    "    kl = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return (recon + kl) / x.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6375401a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ae(epochs):\n",
    "    model_ae = AE(latent_dim=32).to(device)\n",
    "    optimizer = optim.Adam(model_ae.parameters(), lr=1e-3)\n",
    "    criterion = nn.MSELoss()\n",
    "    model_ae.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for x, _ in train_loader:\n",
    "            x = x.to(device)\n",
    "            x_hat, _ = model_ae(x)\n",
    "\n",
    "            loss = criterion(x_hat, x)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # print(f\"Epoch {epoch+1} - Loss = {total_loss/len(train_loader):.4f}\")\n",
    "    \n",
    "    return model_ae\n",
    "\n",
    "\n",
    "def train_vae(epochs):\n",
    "    model_vae = VAE(latent_dim=16).to(device)\n",
    "    opt = optim.Adam(model_vae.parameters(), lr=1e-3)\n",
    "\n",
    "    model_vae.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total = 0\n",
    "        for x, _ in train_loader:\n",
    "            x = x.to(device)\n",
    "            x_hat, mu, logvar, _ = model_vae(x)\n",
    "            \n",
    "            loss = vae_loss(x_hat, x, mu, logvar)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "            total += loss.item()\n",
    "        \n",
    "        # print(f\"Epoch {epoch+1} — Loss = {total/len(train_loader):.4f}\")\n",
    "    \n",
    "    return model_vae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "182fcc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ae_get_latent(model, loader):\n",
    "    model.eval()\n",
    "    Z, Y = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            _, z = model(x)\n",
    "            Z.append(z.cpu().numpy())\n",
    "            Y.append(y.numpy())\n",
    "    return np.vstack(Z), np.hstack(Y)\n",
    "\n",
    "def vae_get_latent(model, loader):\n",
    "    model.eval()\n",
    "    Z, Y = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            _, mu, _, _ = model(x)\n",
    "            Z.append(mu.cpu().numpy())\n",
    "            Y.append(y.numpy())\n",
    "    return np.vstack(Z), np.hstack(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "412290b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_model_performance(test_cluster, test_y, test_z):\n",
    "    nmi = normalized_mutual_info_score(test_y, test_cluster)\n",
    "    ari = adjusted_rand_score(test_y, test_cluster)\n",
    "    sil = silhouette_score(test_z, test_cluster)\n",
    "\n",
    "    print(\"NMI:\", nmi)\n",
    "    print(\"ARI:\", ari)\n",
    "    print(\"Silhouette:\", sil)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfd9b970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ae_kmeans(train_epochs):\n",
    "    model_ae = train_ae(epochs=train_epochs)\n",
    "    train_z, train_y = ae_get_latent(model=model_ae, loader=train_loader)\n",
    "    test_z,  test_y  = ae_get_latent(model=model_ae, loader=test_loader)\n",
    "    \n",
    "    print('Test on AutoEncoder (AE) + KMeans:')\n",
    "    kmeans = KMeans(n_clusters=10, random_state=42)\n",
    "    kmeans.fit(train_z)\n",
    "\n",
    "    test_cluster = kmeans.predict(test_z)\n",
    "    calculate_model_performance(test_cluster, test_y, test_z)\n",
    "\n",
    "def test_vae_gmm(train_epochs):\n",
    "    model_vae = train_vae(epochs=train_epochs)\n",
    "    train_z, train_y = vae_get_latent(model=model_vae, loader=train_loader)\n",
    "    test_z,  test_y  = vae_get_latent(model=model_vae, loader=test_loader)\n",
    "\n",
    "    print('Test on Variational AutoEncoder (VAE) + Gaussian Mixture Model (GMM):')\n",
    "    gmm = GaussianMixture(n_components=10, covariance_type='full', random_state=42)\n",
    "    gmm.fit(train_z)\n",
    "\n",
    "    test_cluster = gmm.predict(test_z)\n",
    "    calculate_model_performance(test_cluster, test_y, test_z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0a3141c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test on AutoEncoder (AE) + KMeans:\n",
      "NMI: 0.5185857007930816\n",
      "ARI: 0.32855891953647626\n",
      "Silhouette: 0.16779543459415436\n",
      "\n",
      "\n",
      "\n",
      "Test on Variational AutoEncoder (VAE) + Gaussian Mixture Model (GMM):\n",
      "NMI: 0.5906259569507099\n",
      "ARI: 0.43468771386721\n",
      "Silhouette: 0.15230272710323334\n"
     ]
    }
   ],
   "source": [
    "test_ae_kmeans(20)\n",
    "print('\\n\\n')\n",
    "test_vae_gmm(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".kenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
